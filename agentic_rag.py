from typing import List, Dict, Optional, Tuple
import json
from recursive_text_splitter import RecursiveTextSplitter
from knowledge_database import VectorDatabase
from chat import chat


class AgenticRAG:
    """
    å…·æœ‰åæ€èƒ½åŠ›çš„æ™ºèƒ½RAGç³»ç»Ÿ
    èƒ½å¤Ÿæ ¹æ®å›ç­”è´¨é‡è¿›è¡Œåæ€ï¼Œå¹¶é‡æ–°æœç´¢ç›¸å…³ä¿¡æ¯
    """
    
    def __init__(self, collection_name: str = "agentic_rag", max_iterations: int = 3):
        """
        åˆå§‹åŒ–Agentic RAGç³»ç»Ÿ
        
        Args:
            collection_name: å‘é‡æ•°æ®åº“é›†åˆåç§°
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        """
        self.db = VectorDatabase()
        self.collection_name = collection_name
        self.max_iterations = max_iterations
        self.conversation_history = []
        
    def setup_knowledge_base(self, documents: List[str], metadata: List[Dict] = None):
        """
        è®¾ç½®çŸ¥è¯†åº“
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            metadata: å¯é€‰çš„å…ƒæ•°æ®åˆ—è¡¨
        """
        # åˆ›å»ºé›†åˆ
        self.db.create_collection(self.collection_name, dimension=1024, drop_if_exists=True)
        
        # æ–‡æœ¬åˆ†å‰²
        splitter = RecursiveTextSplitter(chunk_size=500)
        all_chunks = []
        all_metadata = []
        
        for i, doc in enumerate(documents):
            chunks = splitter.split_text(doc)
            all_chunks.extend(chunks)
            
            # ä¸ºæ¯ä¸ªchunkæ·»åŠ å…ƒæ•°æ®
            for chunk in chunks:
                chunk_metadata = {"doc_id": i, "chunk_text": chunk}
                if metadata and i < len(metadata):
                    chunk_metadata.update(metadata[i])
                all_metadata.append(chunk_metadata)
        
        # æ’å…¥å‘é‡æ•°æ®åº“
        self.db.insert_documents(self.collection_name, all_chunks, all_metadata)
        print(f"çŸ¥è¯†åº“è®¾ç½®å®Œæˆï¼Œå…±æ’å…¥ {len(all_chunks)} ä¸ªæ–‡æ¡£å—")
    
    def initial_search(self, query: str, limit: int = 5) -> List[Dict]:
        """
        åˆå§‹æœç´¢
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            limit: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        results = self.db.search(self.collection_name, query, limit=limit)
        print("\n=== åˆå§‹æœç´¢ ===")
        print(f"æŸ¥è¯¢: {query}")
        print(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
        return results
    
    def generate_initial_answer(self, query: str, search_results: List[Dict]) -> str:
        """
        åŸºäºåˆå§‹æœç´¢ç»“æœç”Ÿæˆå›ç­”
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            search_results: æœç´¢ç»“æœ
            
        Returns:
            ç”Ÿæˆçš„å›ç­”
        """
        context = "\n".join([f"æ–‡æ¡£{i+1}: {r['text']}" for i, r in enumerate(search_results)])
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚é‡è¦æé†’ï¼šè¯·ä¸¥æ ¼åŸºäºæä¾›çš„å‚è€ƒæ–‡æ¡£å›ç­”ï¼Œä¸è¦æé€ æˆ–ç¼–é€ æ–‡æ¡£ä¸­ä¸å­˜åœ¨çš„ä¿¡æ¯ã€‚å¦‚æœæ–‡æ¡£å†…å®¹ä¸è¶³ä»¥å®Œå…¨å›ç­”é—®é¢˜ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºéœ€è¦æ›´å¤šä¿¡æ¯çš„æ–¹é¢ï¼Œä¸è¦è¿›è¡Œæ¨æµ‹æˆ–å‡è®¾ã€‚"},
            {"role": "user", "content": f"åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š\n\næ–‡æ¡£å†…å®¹ï¼š\n{context}\n\né—®é¢˜ï¼š{query}"}
        ]
        
        response = chat(messages)
        answer = response.choices[0].message.content
        print("\n=== åˆå§‹å›ç­” ===")
        print(answer)
        return answer
    
    def reflect_on_answer(self, query: str, answer: str, search_results: List[Dict]) -> Dict:
        """
        å¯¹å›ç­”è¿›è¡Œåæ€å’Œè¯„ä¼°
        
        Args:
            query: åŸå§‹æŸ¥è¯¢
            answer: ç”Ÿæˆçš„å›ç­”
            search_results: æœç´¢ç»“æœ
            
        Returns:
            åæ€ç»“æœå­—å…¸ï¼ŒåŒ…å«è´¨é‡è¯„åˆ†ã€é—®é¢˜åˆ†æå’Œæ”¹è¿›å»ºè®®
        """
        context_summary = f"å…±æ£€ç´¢åˆ°{len(search_results)}ä¸ªæ–‡æ¡£ç‰‡æ®µ"
        
        reflection_prompt = f"""
        è¯·å¯¹ä»¥ä¸‹é—®ç­”è¿›è¡Œåæ€å’Œè¯„ä¼°ï¼š

        ç”¨æˆ·é—®é¢˜ï¼š{query}
        
        æ£€ç´¢ä¸Šä¸‹æ–‡ï¼š{context_summary}
        
        ç”Ÿæˆçš„å›ç­”ï¼š{answer}

        è¯·ä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦è¿›è¡Œè¯„ä¼°å¹¶ç»™å‡ºJSONæ ¼å¼çš„ç»“æœï¼š
        1. å›ç­”è´¨é‡è¯„åˆ† (1-10åˆ†)
        2. å›ç­”æ˜¯å¦å……åˆ†è§£å†³äº†é—®é¢˜
        3. å›ç­”æ˜¯å¦ä¸¥æ ¼åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹ï¼Œæ²¡æœ‰æé€ ä¸å­˜åœ¨çš„ä¿¡æ¯
        4. æ˜¯å¦éœ€è¦æ›´å¤šä¿¡æ¯
        5. å¦‚æœéœ€è¦æ”¹è¿›ï¼Œåº”è¯¥æœç´¢ä»€ä¹ˆå…³é”®è¯
        6. é—®é¢˜åˆ†æå’Œæ”¹è¿›å»ºè®®

        è¿”å›æ ¼å¼ï¼š
        {{
            "quality_score": è¯„åˆ†(1-10),
            "is_sufficient": true/false,
            "is_factual": true/false,
            "needs_more_info": true/false,
            "suggested_keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
            "analysis": "é—®é¢˜åˆ†æ",
            "improvement_suggestions": "æ”¹è¿›å»ºè®®"
        }}
        """
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå›ç­”è´¨é‡è¯„ä¼°ä¸“å®¶ã€‚è¯·å®¢è§‚è¯„ä¼°å›ç­”è´¨é‡å¹¶æä¾›æ”¹è¿›å»ºè®®ã€‚ç‰¹åˆ«å…³æ³¨å›ç­”æ˜¯å¦ä¸¥æ ¼åŸºäºæä¾›çš„æ£€ç´¢å†…å®¹ï¼Œæ˜¯å¦å­˜åœ¨æé€ æˆ–ç¼–é€ ä¿¡æ¯çš„æƒ…å†µã€‚"},
            {"role": "user", "content": reflection_prompt}
        ]
        
        response = chat(messages)
        reflection_text = response.choices[0].message.content
        
        try:
            # å°è¯•è§£æJSON
            reflection = json.loads(reflection_text)
        except json.JSONDecodeError:
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œæä¾›é»˜è®¤ç»“æ„
            reflection = {
                "quality_score": 5,
                "is_sufficient": False,
                "is_factual": True,
                "needs_more_info": True,
                "suggested_keywords": [query],
                "analysis": "æ— æ³•è§£æåæ€ç»“æœ",
                "improvement_suggestions": "å»ºè®®é‡æ–°æœç´¢"
            }
        
        print("\n=== åæ€ç»“æœ ===")
        print(f"è´¨é‡è¯„åˆ†: {reflection.get('quality_score', 'N/A')}/10")
        print(f"å›ç­”æ˜¯å¦å……åˆ†: {reflection.get('is_sufficient', 'N/A')}")
        print(f"äº‹å®å‡†ç¡®æ€§: {reflection.get('is_factual', 'N/A')}")
        print(f"éœ€è¦æ›´å¤šä¿¡æ¯: {reflection.get('needs_more_info', 'N/A')}")
        print(f"å»ºè®®æœç´¢å…³é”®è¯: {reflection.get('suggested_keywords', [])}")
        print(f"åˆ†æ: {reflection.get('analysis', 'N/A')}")
        
        return reflection
    
    def refined_search(self, original_query: str, reflection: Dict, previous_results: List[Dict]) -> List[Dict]:
        """
        åŸºäºåæ€ç»“æœè¿›è¡Œç²¾ç»†åŒ–æœç´¢
        
        Args:
            original_query: åŸå§‹æŸ¥è¯¢
            reflection: åæ€ç»“æœ
            previous_results: ä¹‹å‰çš„æœç´¢ç»“æœ
            
        Returns:
            æ–°çš„æœç´¢ç»“æœ
        """
        suggested_keywords = reflection.get('suggested_keywords', [])
        
        # æ„å»ºæ–°çš„æœç´¢æŸ¥è¯¢
        if suggested_keywords:
            new_query = f"{original_query} {' '.join(suggested_keywords)}"
        else:
            new_query = original_query
        
        # æ‰§è¡Œæ–°æœç´¢
        new_results = self.db.search(self.collection_name, new_query, limit=8)
        
        # å»é‡ï¼šç§»é™¤ä¸ä¹‹å‰ç»“æœé‡å¤çš„å†…å®¹
        previous_texts = {r['text'] for r in previous_results}
        unique_results = [r for r in new_results if r['text'] not in previous_texts]
        
        print("\n=== ç²¾ç»†åŒ–æœç´¢ ===")
        print(f"æ–°æŸ¥è¯¢: {new_query}")
        print(f"æ‰¾åˆ° {len(new_results)} ä¸ªç»“æœï¼Œå…¶ä¸­ {len(unique_results)} ä¸ªæ˜¯æ–°å†…å®¹")
        
        return unique_results
    
    def generate_improved_answer(self, query: str, all_search_results: List[Dict], iteration: int) -> str:
        """
        åŸºäºæ‰€æœ‰æœç´¢ç»“æœç”Ÿæˆæ”¹è¿›çš„å›ç­”
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            all_search_results: æ‰€æœ‰æœç´¢ç»“æœ
            iteration: å½“å‰è¿­ä»£æ¬¡æ•°
            
        Returns:
            æ”¹è¿›çš„å›ç­”
        """
        context = "\n".join([f"æ–‡æ¡£{i+1}: {r['text']}" for i, r in enumerate(all_search_results)])
        
        messages = [
            {"role": "system", "content": f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¿™æ˜¯ç¬¬{iteration}æ¬¡è¿­ä»£ä¼˜åŒ–ã€‚è¯·åŸºäºæä¾›çš„æ‰€æœ‰æ–‡æ¡£å†…å®¹ç»™å‡ºæœ€å…¨é¢ã€å‡†ç¡®çš„å›ç­”ã€‚é‡è¦æé†’ï¼šè¯·ä¸¥æ ¼åŸºäºæä¾›çš„å‚è€ƒæ–‡æ¡£å›ç­”ï¼Œä¸è¦æé€ æˆ–ç¼–é€ æ–‡æ¡£ä¸­ä¸å­˜åœ¨çš„ä¿¡æ¯ï¼Œä¸è¦è¿›è¡Œæ— æ ¹æ®çš„æ¨æµ‹æˆ–å‡è®¾ã€‚"},
            {"role": "user", "content": f"åŸºäºä»¥ä¸‹æ‰€æœ‰æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š\n\næ–‡æ¡£å†…å®¹ï¼š\n{context}\n\né—®é¢˜ï¼š{query}"}
        ]
        
        response = chat(messages)
        improved_answer = response.choices[0].message.content
        print(f"\n=== ç¬¬{iteration}æ¬¡æ”¹è¿›å›ç­” ===")
        print(improved_answer)
        return improved_answer
    
    def query(self, user_query: str) -> Dict:
        """
        æ‰§è¡ŒAgentic RAGæŸ¥è¯¢æµç¨‹
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            åŒ…å«æœ€ç»ˆç­”æ¡ˆå’Œå¤„ç†è¿‡ç¨‹çš„å­—å…¸
        """
        print(f"\n{'='*60}")
        print("å¼€å§‹Agentic RAGæŸ¥è¯¢æµç¨‹")
        print(f"ç”¨æˆ·é—®é¢˜: {user_query}")
        print(f"{'='*60}")
        
        # 1. åˆå§‹æœç´¢å’Œå›ç­”
        search_results = self.initial_search(user_query)
        current_answer = self.generate_initial_answer(user_query, search_results)
        
        all_search_results = search_results.copy()
        iteration_history = []
        
        # 2. è¿­ä»£æ”¹è¿›æµç¨‹
        for iteration in range(1, self.max_iterations + 1):
            print(f"\n--- ç¬¬{iteration}æ¬¡è¿­ä»£ ---")
            
            # åæ€å½“å‰å›ç­”
            reflection = self.reflect_on_answer(user_query, current_answer, all_search_results)
            
            # è®°å½•è¿­ä»£å†å²
            iteration_info = {
                "iteration": iteration,
                "answer": current_answer,
                "reflection": reflection,
                "search_results_count": len(all_search_results)
            }
            iteration_history.append(iteration_info)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­æ”¹è¿›
            quality_score = reflection.get('quality_score', 0)
            is_sufficient = reflection.get('is_sufficient', False)
            
            if quality_score >= 8 and is_sufficient:
                print(f"å›ç­”è´¨é‡è¾¾åˆ°è¦æ±‚ (è¯„åˆ†: {quality_score}/10)ï¼Œåœæ­¢è¿­ä»£")
                break
            
            if not reflection.get('needs_more_info', True):
                print("åæ€ç»“æœæ˜¾ç¤ºä¸éœ€è¦æ›´å¤šä¿¡æ¯ï¼Œåœæ­¢è¿­ä»£")
                break
            
            # è¿›è¡Œç²¾ç»†åŒ–æœç´¢
            new_results = self.refined_search(user_query, reflection, all_search_results)
            
            if not new_results:
                print("æ²¡æœ‰æ‰¾åˆ°æ–°çš„ç›¸å…³ä¿¡æ¯ï¼Œåœæ­¢è¿­ä»£")
                break
            
            # åˆå¹¶æœç´¢ç»“æœ
            all_search_results.extend(new_results)
            
            # ç”Ÿæˆæ”¹è¿›çš„å›ç­”
            current_answer = self.generate_improved_answer(user_query, all_search_results, iteration)
        
        # 3. è¿”å›æœ€ç»ˆç»“æœ
        final_result = {
            "query": user_query,
            "final_answer": current_answer,
            "total_search_results": len(all_search_results),
            "iterations": len(iteration_history),
            "iteration_history": iteration_history,
            "all_search_results": all_search_results
        }
        
        print(f"\n{'='*60}")
        print("Agentic RAGæŸ¥è¯¢å®Œæˆ")
        print(f"æ€»è¿­ä»£æ¬¡æ•°: {len(iteration_history)}")
        print(f"æœ€ç»ˆæ£€ç´¢æ–‡æ¡£æ•°: {len(all_search_results)}")
        print(f"{'='*60}")
        
        return final_result


def build_agentic_rag_demo():
    """æ„å»ºå’Œæµ‹è¯•Agentic RAGç³»ç»Ÿ"""
    
    # åˆ›å»ºAgentic RAGå®ä¾‹
    agentic_rag = AgenticRAG(collection_name="agentic_demo", max_iterations=3)
    
    # å‡†å¤‡çŸ¥è¯†åº“æ–‡æ¡£
    documents = [
        """
        äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼Œç®€ç§°AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œ
        å¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚è¯¥é¢†åŸŸçš„ç ”ç©¶åŒ…æ‹¬æœºå™¨äººã€
        è¯­è¨€è¯†åˆ«ã€å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œä¸“å®¶ç³»ç»Ÿç­‰ã€‚äººå·¥æ™ºèƒ½ä»è¯ç”Ÿä»¥æ¥ï¼Œç†è®ºå’ŒæŠ€æœ¯æ—¥ç›Šæˆç†Ÿï¼Œ
        åº”ç”¨é¢†åŸŸä¹Ÿä¸æ–­æ‰©å¤§ã€‚
        """,
        """
        æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ã€‚å®ƒæ˜¯ä¸€ç§é€šè¿‡ç®—æ³•è§£ææ•°æ®ã€ä»ä¸­å­¦ä¹ ï¼Œç„¶åå¯¹çœŸå®ä¸–ç•Œ
        ä¸­çš„äº‹ä»¶åšå‡ºå†³ç­–å’Œé¢„æµ‹çš„æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿçš„ä¸ºè§£å†³ç‰¹å®šä»»åŠ¡ã€ç¡¬ç¼–ç çš„è½¯ä»¶ç¨‹åºä¸åŒï¼Œæœºå™¨å­¦ä¹ 
        æ˜¯ç”¨å¤§é‡çš„æ•°æ®æ¥"è®­ç»ƒ"ï¼Œé€šè¿‡å„ç§ç®—æ³•ä»æ•°æ®ä¸­å­¦ä¹ å¦‚ä½•å®Œæˆä»»åŠ¡ã€‚å¸¸è§çš„æœºå™¨å­¦ä¹ ç®—æ³•åŒ…æ‹¬
        çº¿æ€§å›å½’ã€å†³ç­–æ ‘ã€éšæœºæ£®æ—ã€æ”¯æŒå‘é‡æœºå’Œç¥ç»ç½‘ç»œç­‰ã€‚
        """,
        """
        æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒæ¨¡æ‹Ÿäººè„‘çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œé€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„è¡¨ç¤ºã€‚
        æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰
        ä¸»è¦ç”¨äºå›¾åƒå¤„ç†ï¼Œå¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å’Œé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰ä¸»è¦ç”¨äºåºåˆ—æ•°æ®å¤„ç†ï¼Œ
        è€ŒTransformeræ¶æ„åˆ™åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§å˜åŒ–ã€‚
        """,
        """
        è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNatural Language Processingï¼Œç®€ç§°NLPï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åº”ç”¨é¢†åŸŸï¼Œ
        å®ƒç ”ç©¶å¦‚ä½•è®©è®¡ç®—æœºç†è§£ã€å¤„ç†å’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚NLPçš„ä¸»è¦ä»»åŠ¡åŒ…æ‹¬æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æã€
        æœºå™¨ç¿»è¯‘ã€é—®ç­”ç³»ç»Ÿã€æ–‡æœ¬æ‘˜è¦ç­‰ã€‚è¿‘å¹´æ¥ï¼ŒåŸºäºTransformerçš„å¤§å‹è¯­è¨€æ¨¡å‹å¦‚GPTã€BERT
        ç­‰çš„å‡ºç°ï¼Œå¤§å¤§æ¨åŠ¨äº†NLPæŠ€æœ¯çš„å‘å±•ã€‚
        """,
        """
        è®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½çš„å¦ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿ"çœ‹æ‡‚"å›¾åƒå’Œè§†é¢‘ã€‚
        è®¡ç®—æœºè§†è§‰çš„ä¸»è¦ä»»åŠ¡åŒ…æ‹¬å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²ã€äººè„¸è¯†åˆ«ç­‰ã€‚æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œ
        ç‰¹åˆ«æ˜¯å·ç§¯ç¥ç»ç½‘ç»œçš„å‘å±•ï¼Œä½¿å¾—è®¡ç®—æœºè§†è§‰åœ¨è®¸å¤šä»»åŠ¡ä¸Šè¾¾åˆ°ç”šè‡³è¶…è¶Šäº†äººç±»çš„è¡¨ç°ã€‚
        """,
        """
        äººå·¥æ™ºèƒ½çš„åº”ç”¨é¢†åŸŸéå¸¸å¹¿æ³›ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼šåŒ»ç–—è¯Šæ–­ã€é‡‘èé£æ§ã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½æ¨èã€
        è¯­éŸ³åŠ©æ‰‹ã€æœºå™¨ç¿»è¯‘ã€æ¸¸æˆAIç­‰ã€‚éšç€æŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼ŒAIæ­£åœ¨æ”¹å˜å„ä¸ªè¡Œä¸šçš„å·¥ä½œæ–¹å¼ï¼Œ
        æé«˜æ•ˆç‡ï¼Œåˆ›é€ æ–°çš„å•†ä¸šæ¨¡å¼ã€‚åŒæ—¶ï¼ŒAIçš„å‘å±•ä¹Ÿå¸¦æ¥äº†ä¸€äº›æŒ‘æˆ˜ï¼Œå¦‚å°±ä¸šå½±å“ã€éšç§ä¿æŠ¤ã€
        ç®—æ³•åè§ç­‰é—®é¢˜ï¼Œéœ€è¦ç¤¾ä¼šå„ç•Œå…±åŒå…³æ³¨å’Œè§£å†³ã€‚
        """
    ]
    
    # å‡†å¤‡å…ƒæ•°æ®
    metadata = [
        {"category": "AIåŸºç¡€", "topic": "äººå·¥æ™ºèƒ½å®šä¹‰", "difficulty": "åˆçº§"},
        {"category": "æœºå™¨å­¦ä¹ ", "topic": "æœºå™¨å­¦ä¹ æ¦‚è¿°", "difficulty": "ä¸­çº§"},
        {"category": "æ·±åº¦å­¦ä¹ ", "topic": "æ·±åº¦å­¦ä¹ æŠ€æœ¯", "difficulty": "é«˜çº§"},
        {"category": "NLP", "topic": "è‡ªç„¶è¯­è¨€å¤„ç†", "difficulty": "ä¸­çº§"},
        {"category": "è®¡ç®—æœºè§†è§‰", "topic": "å›¾åƒå¤„ç†", "difficulty": "ä¸­çº§"},
        {"category": "AIåº”ç”¨", "topic": "åº”ç”¨åœºæ™¯", "difficulty": "åˆçº§"}
    ]
    
    # è®¾ç½®çŸ¥è¯†åº“
    agentic_rag.setup_knowledge_base(documents, metadata)
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿå®ƒæœ‰å“ªäº›ä¸»è¦åº”ç”¨é¢†åŸŸï¼Ÿ",
        "æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
        "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸæœ‰å“ªäº›å…·ä½“åº”ç”¨ï¼Ÿ"
    ]
    
    # æ‰§è¡Œæµ‹è¯•
    for i, query in enumerate(test_queries, 1):
        print(f"\n\nğŸ” æµ‹è¯•æŸ¥è¯¢ {i}: {query}")
        agentic_rag.query(query)


if __name__ == "__main__":
    build_agentic_rag_demo()
